{
    "hidden_size": 128,
    "num_attention_heads": 16,
    "num_key_value_heads": 4,
    "max_position_embeddings": 256,
    "rope_theta": 10000.0,
    "attention_bias": False,
    "use_qk_norm": True,
    "intermediate_size": intermediate_size,
    "hidden_act": "silu",
    "ffn_bias": False,
    "rms_norm_eps": 1e-5
}